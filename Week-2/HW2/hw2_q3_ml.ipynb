{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed8f7ee4edc2ff6",
   "metadata": {},
   "source": [
    "# 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f0c4de84929ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:45.795032Z",
     "start_time": "2025-09-29T00:40:44.796104Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8fde4076ac9a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:45.817733Z",
     "start_time": "2025-09-29T00:40:45.804595Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"spambase/spambase.data\", delimiter=\",\")\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50f08f8a3b5bd1",
   "metadata": {},
   "source": [
    "1. SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e345f7e8b70ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:46.061042Z",
     "start_time": "2025-09-29T00:40:45.823524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1. LINEAR KERNEL SVM\n",
      "============================================================\n",
      "Train Accuracy: 0.9323\n",
      "Test Accuracy: 0.9251\n",
      "Number of Support Vectors: 772\n",
      "Training Time: 0.23 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 1. LINEAR KERNEL SVM\")\n",
    "print(\"=\"*60)\n",
    "start_time = time.time()\n",
    "\n",
    "# train linear svm:\n",
    "svm_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "train_pred_linear = svm_linear.predict(X_train)\n",
    "test_pred_linear = svm_linear.predict(X_test)\n",
    "\n",
    "train_acc_linear = np.mean(train_pred_linear == y_train)\n",
    "test_acc_linear = np.mean(test_pred_linear == y_test)\n",
    "\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_linear:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_linear:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_linear.n_support_)}\")\n",
    "print(f\"Training Time: {linear_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afcf5a077ace67",
   "metadata": {},
   "source": [
    "2. Training SVM with RBF Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da880decf696c74e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:46.379919Z",
     "start_time": "2025-09-29T00:40:46.065395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2. RBF Kernel SVM\n",
      "============================================================\n",
      "Train Accuracy: 0.9454\n",
      "Test Accuracy: 0.9349\n",
      "Number of Support Vectors: 1084\n",
      "Training Time: 0.31 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 2. RBF Kernel SVM\")\n",
    "print(\"=\"*60)\n",
    "start_time = time.time()\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "train_pred_rbf = svm_rbf.predict(X_train)\n",
    "test_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "train_acc_rbf = np.mean(train_pred_rbf==y_train)\n",
    "test_acc_rbf = np.mean(test_pred_rbf==y_test)\n",
    "\n",
    "rbf_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_rbf:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_rbf:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_rbf.n_support_)}\")\n",
    "print(f\"Training Time: {rbf_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afa7d06f9edea9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:46.559738Z",
     "start_time": "2025-09-29T00:40:46.383585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. POLYNOMIAL KERNEL SVM\n",
      "============================================================\n",
      "Train Accuracy: 0.8978\n",
      "Test Accuracy: 0.8578\n",
      "Number of Support Vectors: 1495\n",
      "Training Time: 0.17 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. POLYNOMIAL KERNEL SVM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=10.0, gamma='scale', random_state=42)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "train_pred_poly = svm_poly.predict(X_train)\n",
    "test_pred_poly = svm_poly.predict(X_test)\n",
    "\n",
    "train_acc_poly = np.mean(train_pred_poly == y_train)\n",
    "test_acc_poly = np.mean(test_pred_poly == y_test)\n",
    "\n",
    "poly_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_poly:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_poly:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_poly.n_support_)}\")\n",
    "print(f\"Training Time: {poly_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59a02f0d7b3b3ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:48.671498Z",
     "start_time": "2025-09-29T00:40:46.566832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING\n",
      "============================================================\n",
      "\n",
      "Testing LINEAR kernel with different C values:\n",
      "----------------------------------------\n",
      "  C= 0.1: Test Accuracy = 0.9218\n",
      "  C= 1.0: Test Accuracy = 0.9251\n",
      "  C=10.0: Test Accuracy = 0.9229\n",
      "\n",
      "Testing RBF kernel with different C values:\n",
      "----------------------------------------\n",
      "  C= 0.1: Test Accuracy = 0.9088\n",
      "  C= 1.0: Test Accuracy = 0.9349\n",
      "  C=10.0: Test Accuracy = 0.9381\n",
      "\n",
      "Testing POLY kernel with different C values:\n",
      "----------------------------------------\n",
      "  C= 0.1: Test Accuracy = 0.6862\n",
      "  C= 1.0: Test Accuracy = 0.7644\n",
      "  C=10.0: Test Accuracy = 0.8578\n"
     ]
    }
   ],
   "source": [
    "# Try different C values and parameters\n",
    "def test_hyperparameters():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    C_values = [0.1, 1.0, 10.0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for kernel_type in ['linear', 'rbf', 'poly']:\n",
    "        print(f\"\\nTesting {kernel_type.upper()} kernel with different C values:\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        kernel_results = []\n",
    "\n",
    "        for C in C_values:\n",
    "            if kernel_type == 'linear':\n",
    "                svm = SVC(kernel='linear', C=C, random_state=42)\n",
    "            elif kernel_type == 'rbf':\n",
    "                svm = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "            else:\n",
    "                svm = SVC(kernel='poly', C=C, degree=3, gamma='scale', random_state=42)\n",
    "\n",
    "            svm.fit(X_train, y_train)\n",
    "            test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "            kernel_results.append((C, test_acc))\n",
    "            print(f\"  C={C:4.1f}: Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "        results[kernel_type] = kernel_results\n",
    "\n",
    "    return results\n",
    "\n",
    "hp_results = test_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a62d5fb06609a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:48.713979Z",
     "start_time": "2025-09-29T00:40:48.711067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEM 3A: SPAMBASE SVM RESULTS SUMMARY\n",
      "================================================================================\n",
      "Kernel       Train Acc    Test Acc     Support Vectors    Time (s)  \n",
      "----------------------------------------------------------------------\n",
      "Linear       0.9323       0.9251       772                0.23      \n",
      "RBF          0.9454       0.9349       1084               0.31      \n",
      "Polynomial   0.8978       0.8578       1495               0.17      \n"
     ]
    }
   ],
   "source": [
    "def print_summary_table():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEM 3A: SPAMBASE SVM RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    results_data = [\n",
    "        [\"Linear\", train_acc_linear, test_acc_linear, sum(svm_linear.n_support_), linear_time],\n",
    "        [\"RBF\", train_acc_rbf, test_acc_rbf, sum(svm_rbf.n_support_), rbf_time],\n",
    "        [\"Polynomial\", train_acc_poly, test_acc_poly, sum(svm_poly.n_support_), poly_time]\n",
    "    ]\n",
    "\n",
    "    print(f\"{'Kernel':<12} {'Train Acc':<12} {'Test Acc':<12} {'Support Vectors':<18} {'Time (s)':<10}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for row in results_data:\n",
    "        kernel, train, test, sv, time_s = row\n",
    "        print(f\"{kernel:<12} {train:<12.4f} {test:<12.4f} {sv:<18} {time_s:<10.2f}\")\n",
    "\n",
    "def check_expectation(kernel, accuracy):\n",
    "    if kernel == 'Linear':\n",
    "        return 0.89 <= accuracy <= 0.93\n",
    "    elif kernel == 'RBF':\n",
    "        return 0.93 <= accuracy <= 0.97\n",
    "    else:\n",
    "        return 0.85 <= accuracy <= 0.90\n",
    "\n",
    "print_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3a1ef27b6567a",
   "metadata": {},
   "source": [
    "# 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2274df75092eb48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:49.124058Z",
     "start_time": "2025-09-29T00:40:48.723302Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_digits = np.loadtxt(\"mnist_haar_bingyu/training_image.txt\", delimiter=\",\")\n",
    "y_train_digits = np.loadtxt(\"mnist_haar_bingyu/training_label.txt\", delimiter=\",\")\n",
    "X_test_digits = np.loadtxt(\"mnist_haar_bingyu/testing_image.txt\", delimiter=\",\")\n",
    "y_test_digits = np.loadtxt(\"mnist_haar_bingyu/testing_label.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b77d764a247fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:49.132843Z",
     "start_time": "2025-09-29T00:40:49.129954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60000, 200)\n",
      "Training labels shape: (60000,)\n",
      "Test set shape: (10000, 200)\n",
      "Test labels shape: (10000,)\n",
      "Number of classes: 10\n",
      "Features per sample: 200 (HAAR features)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {X_train_digits.shape}\")\n",
    "print(f\"Training labels shape: {y_train_digits.shape}\")\n",
    "print(f\"Test set shape: {X_test_digits.shape}\")\n",
    "print(f\"Test labels shape: {y_test_digits.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train_digits))}\")\n",
    "print(f\"Features per sample: {X_train_digits.shape[1]} (HAAR features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724acb4b7c5343b",
   "metadata": {},
   "source": [
    "Multi-class classification with different kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b3346dca1d6414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:40:49.144723Z",
     "start_time": "2025-09-29T00:40:49.142220Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_svm_multiclass(X_train, y_train, X_test, y_test, kernel_type, **params):\n",
    "    print(f\"\\n {kernel_type.upper()} KERNEL SVM\")\n",
    "    print(\"-\"*40)\n",
    "    start_time = time.time()\n",
    "\n",
    "    if kernel_type == \"linear\":\n",
    "        svm = SVC(kernel=\"linear\", C=params.get('C', 1.0), random_state=42)\n",
    "    elif kernel_type == \"rbf\":\n",
    "        svm = SVC(kernel=\"rbf\", C=params.get('C', 1.0), gamma=params.get('gamma', 'scale'), random_state=42)\n",
    "    elif kernel_type == \"poly\":\n",
    "        svm = SVC(kernel=\"poly\", C=params.get('C', 1.0), degree=params.get('degree', 3), gamma=params.get('gamma', 'scale'), random_state=42)\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = svm.predict(X_train)\n",
    "    test_pred = svm.predict(X_test)\n",
    "\n",
    "    train_acc = np.mean(train_pred == y_train)\n",
    "    test_acc = np.mean(test_pred == y_test)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Total Support Vectors: {sum(svm.n_support_)}\")\n",
    "    print(f\"Support Vectors per class: {svm.n_support_}\")\n",
    "    print(f\"Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return svm, train_acc, test_acc, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76494db00c723b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:59:37.964546Z",
     "start_time": "2025-09-29T00:40:49.151406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROBLEM 3B: DIGITS DATASET WITH HAAR FEATURES\n",
      "============================================================\n",
      "\n",
      " LINEAR KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9537\n",
      "Test Accuracy: 0.9343\n",
      "Total Support Vectors: 9830\n",
      "Support Vectors per class: [ 449  430 1037 1353  962 1351  585  918 1356 1389]\n",
      "Training Time: 1024.41 seconds\n",
      "\n",
      " RBF KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9887\n",
      "Test Accuracy: 0.9761\n",
      "Total Support Vectors: 8244\n",
      "Support Vectors per class: [ 422  414  738 1140  923  967  527  793 1074 1246]\n",
      "Training Time: 55.19 seconds\n",
      "\n",
      " POLY KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9702\n",
      "Test Accuracy: 0.9645\n",
      "Total Support Vectors: 11419\n",
      "Support Vectors per class: [ 687  679  897 1560 1269 1597  654 1101 1330 1645]\n",
      "Training Time: 49.21 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBLEM 3B: DIGITS DATASET WITH HAAR FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_digits = {}\n",
    "\n",
    "# 1. Linear Kernel\n",
    "svm_linear_d, train_lin_d, test_lin_d, time_lin_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'linear', C=1.0\n",
    ")\n",
    "results_digits['linear'] = (train_lin_d, test_lin_d, time_lin_d)\n",
    "\n",
    "# 2. RBF Kernel\n",
    "svm_rbf_d, train_rbf_d, test_rbf_d, time_rbf_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'rbf', C=10.0, gamma='scale'\n",
    ")\n",
    "results_digits['rbf'] = (train_rbf_d, test_rbf_d, time_rbf_d)\n",
    "\n",
    "# 3. Polynomial Kernel\n",
    "svm_poly_d, train_poly_d, test_poly_d, time_poly_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'poly', C=1.0, degree=3\n",
    ")\n",
    "results_digits['poly'] = (train_poly_d, test_poly_d, time_poly_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f368a7bdf4a74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T01:01:05.406736Z",
     "start_time": "2025-09-29T00:59:37.991401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING FOR DIGITS DATASET\n",
      "============================================================\n",
      "\n",
      "Tuning LINEAR kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best parameters: {'C': 0.01}\n",
      "Best CV score: 0.8785\n",
      "Training on full dataset with best parameters...\n",
      "Linear Test Accuracy with best params: 0.9377\n",
      "\n",
      "\n",
      "Tuning RBF kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters: {'C': 10, 'gamma': 'scale'}\n",
      "Best CV score: 0.9215\n",
      "Training on full dataset with best parameters...\n",
      "RBF Test Accuracy with best params: 0.9761\n",
      "\n",
      "\n",
      "Tuning POLY kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best parameters: {'C': 10, 'degree': 2, 'gamma': 'scale'}\n",
      "Best CV score: 0.9200\n",
      "Training on full dataset with best parameters...\n",
      "Polynomial Test Accuracy with best params: 0.9722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_svm_digits(X_train, y_train, kernel_type):\n",
    "    \"\"\"\n",
    "    Find optimal hyperparameters for each kernel on digits dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nTuning {kernel_type.upper()} kernel...\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    if kernel_type == 'linear':\n",
    "        param_grid = {\n",
    "            'C': [0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    elif kernel_type == 'rbf':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "        }\n",
    "    else:  # polynomial\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'degree': [2, 3, 4],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "\n",
    "    svm = SVC(kernel=kernel_type, random_state=42)\n",
    "\n",
    "    # Grid search with 3-fold cross-validation\n",
    "    n_samples = min(2000, len(X_train))\n",
    "    indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "    X_subset = X_train[indices]\n",
    "    y_subset = y_train[indices]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        svm, param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_subset, y_subset)\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    print(\"Training on full dataset with best parameters...\")\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    best_svm.fit(X_train, y_train)\n",
    "\n",
    "    return best_svm, grid_search.best_params_\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING FOR DIGITS DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_linear_svm, best_linear_params = tune_svm_digits(X_train_digits, y_train_digits, 'linear')\n",
    "test_acc_linear = best_linear_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"Linear Test Accuracy with best params: {test_acc_linear:.4f}\\n\")\n",
    "\n",
    "best_rbf_svm, best_rbf_params = tune_svm_digits(X_train_digits, y_train_digits, 'rbf')\n",
    "test_acc_rbf = best_rbf_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"RBF Test Accuracy with best params: {test_acc_rbf:.4f}\\n\")\n",
    "\n",
    "best_poly_svm, best_poly_params = tune_svm_digits(X_train_digits, y_train_digits, 'poly')\n",
    "test_acc_poly = best_poly_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"Polynomial Test Accuracy with best params: {test_acc_poly:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
