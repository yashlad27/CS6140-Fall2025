{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3a",
   "id": "4ed8f7ee4edc2ff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:04:39.914468Z",
     "start_time": "2025-09-25T17:04:39.904872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ],
   "id": "a7f0c4de84929ed1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data pre-processing for SPAMBASE:\n",
    "data = np.loadtxt(\"spambase/spambase.data\", delimiter=\",\")\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)"
   ],
   "id": "9d8fde4076ac9a8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. SVM with Linear Kernel",
   "id": "ea50f08f8a3b5bd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n 1. LINEAR KERNEL SVM\")\n",
    "print(\"=\"*60)\n",
    "start_time = time.time()\n",
    "\n",
    "# train linear svm:\n",
    "svm_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "train_pred_linear = svm_linear.predict(X_train)\n",
    "test_pred_linear = svm_linear.predict(X_test)\n",
    "\n",
    "train_acc_linear = np.mean(train_pred_linear == y_train)\n",
    "test_acc_linear = np.mean(test_pred_linear == y_test)\n",
    "\n",
    "linear_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_linear:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_linear:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_linear.n_support_)}\")\n",
    "print(f\"Training Time: {linear_time:.2f} seconds\")"
   ],
   "id": "53e345f7e8b70ae2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Training SVM with RBF Kernel:",
   "id": "34afcf5a077ace67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n 2. RBF Kernel SVM\")\n",
    "print(\"=\"*60)\n",
    "start_time = time.time()\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "train_pred_rbf = svm_rbf.predict(X_train)\n",
    "test_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "train_acc_rbf = np.mean(train_pred_rbf==y_train)\n",
    "test_acc_rbf = np.mean(test_pred_rbf==y_test)\n",
    "\n",
    "rbf_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_rbf:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_rbf:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_rbf.n_support_)}\")\n",
    "print(f\"Training Time: {rbf_time:.2f} seconds\")"
   ],
   "id": "da880decf696c74e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n3. POLYNOMIAL KERNEL SVM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=10.0, gamma='scale', random_state=42)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "train_pred_poly = svm_poly.predict(X_train)\n",
    "test_pred_poly = svm_poly.predict(X_test)\n",
    "\n",
    "train_acc_poly = np.mean(train_pred_poly == y_train)\n",
    "test_acc_poly = np.mean(test_pred_poly == y_test)\n",
    "\n",
    "poly_time = time.time() - start_time\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc_poly:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_poly:.4f}\")\n",
    "print(f\"Number of Support Vectors: {sum(svm_poly.n_support_)}\")\n",
    "print(f\"Training Time: {poly_time:.2f} seconds\")"
   ],
   "id": "3afa7d06f9edea9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Try different C values and parameters\n",
    "def test_hyperparameters():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Test different C values for each kernel\n",
    "    C_values = [0.1, 1.0, 10.0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for kernel_type in ['linear', 'rbf', 'poly']:\n",
    "        print(f\"\\nTesting {kernel_type.upper()} kernel with different C values:\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "        kernel_results = []\n",
    "\n",
    "        for C in C_values:\n",
    "            if kernel_type == 'linear':\n",
    "                svm = SVC(kernel='linear', C=C, random_state=42)\n",
    "            elif kernel_type == 'rbf':\n",
    "                svm = SVC(kernel='rbf', C=C, gamma='scale', random_state=42)\n",
    "            else:  # poly\n",
    "                svm = SVC(kernel='poly', C=C, degree=3, gamma='scale', random_state=42)\n",
    "\n",
    "            svm.fit(X_train, y_train)\n",
    "            test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "            kernel_results.append((C, test_acc))\n",
    "            print(f\"  C={C:4.1f}: Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "        results[kernel_type] = kernel_results\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run hyperparameter testing\n",
    "hp_results = test_hyperparameters()"
   ],
   "id": "c59a02f0d7b3b3ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_summary_table():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEM 3A: SPAMBASE SVM RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Create results table\n",
    "    results_data = [\n",
    "        [\"Linear\", train_acc_linear, test_acc_linear, sum(svm_linear.n_support_), linear_time],\n",
    "        [\"RBF\", train_acc_rbf, test_acc_rbf, sum(svm_rbf.n_support_), rbf_time],\n",
    "        [\"Polynomial\", train_acc_poly, test_acc_poly, sum(svm_poly.n_support_), poly_time]\n",
    "    ]\n",
    "\n",
    "    print(f\"{'Kernel':<12} {'Train Acc':<12} {'Test Acc':<12} {'Support Vectors':<18} {'Time (s)':<10}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for row in results_data:\n",
    "        kernel, train, test, sv, time_s = row\n",
    "        print(f\"{kernel:<12} {train:<12.4f} {test:<12.4f} {sv:<18} {time_s:<10.2f}\")\n",
    "\n",
    "def check_expectation(kernel, accuracy):\n",
    "    if kernel == 'Linear':\n",
    "        return 0.89 <= accuracy <= 0.93\n",
    "    elif kernel == 'RBF':\n",
    "        return 0.93 <= accuracy <= 0.97\n",
    "    else:  # Polynomial\n",
    "        return 0.85 <= accuracy <= 0.90\n",
    "\n",
    "print_summary_table()"
   ],
   "id": "d4a62d5fb06609a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3B",
   "id": "a8d3a1ef27b6567a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:39.960678Z",
     "start_time": "2025-09-25T17:06:39.586617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_digits = np.loadtxt(\"mnist_haar_bingyu/training_image.txt\", delimiter=\",\")\n",
    "y_train_digits = np.loadtxt(\"mnist_haar_bingyu/training_label.txt\", delimiter=\",\")\n",
    "X_test_digits = np.loadtxt(\"mnist_haar_bingyu/testing_image.txt\", delimiter=\",\")\n",
    "y_test_digits = np.loadtxt(\"mnist_haar_bingyu/testing_label.txt\", delimiter=\",\")"
   ],
   "id": "f2274df75092eb48",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:06:42.765982Z",
     "start_time": "2025-09-25T17:06:42.761168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Training set shape: {X_train_digits.shape}\")\n",
    "print(f\"Training labels shape: {y_train_digits.shape}\")\n",
    "print(f\"Test set shape: {X_test_digits.shape}\")\n",
    "print(f\"Test labels shape: {y_test_digits.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train_digits))}\")\n",
    "print(f\"Features per sample: {X_train_digits.shape[1]} (HAAR features)\")"
   ],
   "id": "38b77d764a247fe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60000, 200)\n",
      "Training labels shape: (60000,)\n",
      "Test set shape: (10000, 200)\n",
      "Test labels shape: (10000,)\n",
      "Number of classes: 10\n",
      "Features per sample: 200 (HAAR features)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multi-class classification with different kernels:",
   "id": "724acb4b7c5343b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:14:15.512415Z",
     "start_time": "2025-09-25T17:14:15.504242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_svm_multiclass(X_train, y_train, X_test, y_test, kernel_type, **params):\n",
    "    print(f\"\\n {kernel_type.upper()} KERNEL SVM\")\n",
    "    print(\"-\"*40)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # SVM modelling:\n",
    "    if kernel_type == \"linear\":\n",
    "        svm = SVC(kernel=\"linear\", C=params.get('C', 1.0), random_state=42)\n",
    "    elif kernel_type == \"rbf\":\n",
    "        svm = SVC(kernel=\"rbf\", C=params.get('C', 1.0), gamma=params.get('gamma', 'scale'), random_state=42)\n",
    "    elif kernel_type == \"poly\":\n",
    "        svm = SVC(kernel=\"poly\", C=params.get('C', 1.0), degree=params.get('degree', 3), gamma=params.get('gamma', 'scale'), random_state=42)\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = svm.predict(X_train)\n",
    "    test_pred = svm.predict(X_test)\n",
    "\n",
    "    train_acc = np.mean(train_pred == y_train)\n",
    "    test_acc = np.mean(test_pred == y_test)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Total Support Vectors: {sum(svm.n_support_)}\")\n",
    "    print(f\"Support Vectors per class: {svm.n_support_}\")\n",
    "    print(f\"Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return svm, train_acc, test_acc, elapsed_time"
   ],
   "id": "f5b3346dca1d6414",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:33:29.060889Z",
     "start_time": "2025-09-25T17:14:23.566631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBLEM 3B: DIGITS DATASET WITH HAAR FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store results\n",
    "results_digits = {}\n",
    "\n",
    "# 1. Linear Kernel\n",
    "svm_linear_d, train_lin_d, test_lin_d, time_lin_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'linear', C=1.0\n",
    ")\n",
    "results_digits['linear'] = (train_lin_d, test_lin_d, time_lin_d)\n",
    "\n",
    "# 2. RBF Kernel\n",
    "svm_rbf_d, train_rbf_d, test_rbf_d, time_rbf_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'rbf', C=10.0, gamma='scale'\n",
    ")\n",
    "results_digits['rbf'] = (train_rbf_d, test_rbf_d, time_rbf_d)\n",
    "\n",
    "# 3. Polynomial Kernel\n",
    "svm_poly_d, train_poly_d, test_poly_d, time_poly_d = train_svm_multiclass(\n",
    "    X_train_digits, y_train_digits, X_test_digits, y_test_digits,\n",
    "    'poly', C=1.0, degree=3\n",
    ")\n",
    "results_digits['poly'] = (train_poly_d, test_poly_d, time_poly_d)"
   ],
   "id": "76494db00c723b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROBLEM 3B: DIGITS DATASET WITH HAAR FEATURES\n",
      "============================================================\n",
      "\n",
      " LINEAR KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9537\n",
      "Test Accuracy: 0.9343\n",
      "Total Support Vectors: 9830\n",
      "Support Vectors per class: [ 449  430 1037 1353  962 1351  585  918 1356 1389]\n",
      "Training Time: 1041.06 seconds\n",
      "\n",
      " RBF KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9887\n",
      "Test Accuracy: 0.9761\n",
      "Total Support Vectors: 8244\n",
      "Support Vectors per class: [ 422  414  738 1140  923  967  527  793 1074 1246]\n",
      "Training Time: 55.01 seconds\n",
      "\n",
      " POLY KERNEL SVM\n",
      "----------------------------------------\n",
      "Train Accuracy: 0.9702\n",
      "Test Accuracy: 0.9645\n",
      "Total Support Vectors: 11419\n",
      "Support Vectors per class: [ 687  679  897 1560 1269 1597  654 1101 1330 1645]\n",
      "Training Time: 49.42 seconds\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T17:47:34.688731Z",
     "start_time": "2025-09-25T17:46:07.008228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_svm_digits(X_train, y_train, kernel_type):\n",
    "    \"\"\"\n",
    "    Find optimal hyperparameters for each kernel on digits dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nTuning {kernel_type.upper()} kernel...\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    # Define parameter grids for each kernel\n",
    "    if kernel_type == 'linear':\n",
    "        param_grid = {\n",
    "            'C': [0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    elif kernel_type == 'rbf':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "        }\n",
    "    else:  # polynomial\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'degree': [2, 3, 4],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "\n",
    "    # Create SVM\n",
    "    svm = SVC(kernel=kernel_type, random_state=42)\n",
    "\n",
    "    # Grid search with 3-fold cross-validation\n",
    "    # Note: We can use a subset of data for faster tuning if needed\n",
    "    # Sample 20% of training data for tuning (to speed up)\n",
    "    n_samples = min(2000, len(X_train))\n",
    "    indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "    X_subset = X_train[indices]\n",
    "    y_subset = y_train[indices]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        svm, param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Use all cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_subset, y_subset)\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Train final model with best parameters on full training set\n",
    "    print(\"Training on full dataset with best parameters...\")\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    best_svm.fit(X_train, y_train)\n",
    "\n",
    "    return best_svm, grid_search.best_params_\n",
    "\n",
    "# Run hyperparameter tuning for each kernel\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING FOR DIGITS DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tune Linear\n",
    "best_linear_svm, best_linear_params = tune_svm_digits(X_train_digits, y_train_digits, 'linear')\n",
    "test_acc_linear = best_linear_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"Linear Test Accuracy with best params: {test_acc_linear:.4f}\\n\")\n",
    "\n",
    "# Tune RBF\n",
    "best_rbf_svm, best_rbf_params = tune_svm_digits(X_train_digits, y_train_digits, 'rbf')\n",
    "test_acc_rbf = best_rbf_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"RBF Test Accuracy with best params: {test_acc_rbf:.4f}\\n\")\n",
    "\n",
    "# Tune Polynomial\n",
    "best_poly_svm, best_poly_params = tune_svm_digits(X_train_digits, y_train_digits, 'poly')\n",
    "test_acc_poly = best_poly_svm.score(X_test_digits, y_test_digits)\n",
    "print(f\"Polynomial Test Accuracy with best params: {test_acc_poly:.4f}\\n\")"
   ],
   "id": "c5f368a7bdf4a74f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING FOR DIGITS DATASET\n",
      "============================================================\n",
      "\n",
      "Tuning LINEAR kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best parameters: {'C': 0.01}\n",
      "Best CV score: 0.8715\n",
      "Training on full dataset with best parameters...\n",
      "Linear Test Accuracy with best params: 0.9377\n",
      "\n",
      "\n",
      "Tuning RBF kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters: {'C': 10, 'gamma': 'scale'}\n",
      "Best CV score: 0.9175\n",
      "Training on full dataset with best parameters...\n",
      "RBF Test Accuracy with best params: 0.9761\n",
      "\n",
      "\n",
      "Tuning POLY kernel...\n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best parameters: {'C': 10, 'degree': 3, 'gamma': 'scale'}\n",
      "Best CV score: 0.9165\n",
      "Training on full dataset with best parameters...\n",
      "Polynomial Test Accuracy with best params: 0.9760\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbd17512b4483bd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
