{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HW2 - Logistic Regression, SVM, Kernels, Duality",
   "id": "84ca1f46756d9a60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Housing Dataset (Linear Regression + Normal Equation)",
   "id": "a209b2d97196ef42"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# housing data set\n",
    "import numpy as np\n",
    "\n",
    "train = np.loadtxt(\"housing_data/train.txt\")\n",
    "test = np.loadtxt(\"housing_data/test.txt\")\n",
    "\n",
    "train"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.shape",
   "id": "a5b92221e18d1637",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# slicing train into X (features) and y (labels)\n",
    "X = train[:, :-1]\n",
    "y = train[:, -1]"
   ],
   "id": "68636d1ad46b42fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.shape",
   "id": "16ea688dd873e643",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.shape",
   "id": "c28aa319f98cca16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# adding bias to the columns\n",
    "ones_col = np.ones((X.shape[0], 1))\n",
    "X_bias = np.hstack([ones_col, X])\n",
    "X_bias.shape"
   ],
   "id": "3907ab66b32e4a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_bias",
   "id": "3bb20acc3e8c71cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using normal equation to calculate best weights ($\\theta$):\n",
    "\n",
    "$\\theta = (X^T X) ^ {-1} X^T Y$"
   ],
   "id": "3265e6adb3a642b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# taking transpose:\n",
    "X_t = X_bias.T\n",
    "\n",
    "# multiplying X_t and X:\n",
    "X_dot = np.dot(X_t, X_bias)\n",
    "\n",
    "# taking inverse:\n",
    "X_inv_1 = np.linalg.inv(X_dot)\n",
    "\n",
    "# calculation for second term\n",
    "Xy_dot = np.dot(X_t, y)\n",
    "\n",
    "best_weights = np.dot(X_inv_1, Xy_dot)\n",
    "best_weights"
   ],
   "id": "592736b0b16446ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluation - using MSE\n",
    "y_pred = np.dot(X_bias, best_weights)\n",
    "\n",
    "# mse calc:\n",
    "mse = np.mean((y_pred - y)**2)\n",
    "mse"
   ],
   "id": "24dba21d40f93036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"First 5 predictions:\", y_pred[:5])\n",
    "print(\"First 5 actual:\", y[:5])\n",
    "print(\"Training MSE:\", mse)"
   ],
   "id": "7da6af372d07a085",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# checking test MSE scores: (Test set evaluation) (test.txt)\n",
    "X_test = test[:, :-1]\n",
    "y_test = test[:,-1]"
   ],
   "id": "68f784c7764f6ed9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test.shape",
   "id": "e60a7e6af992923f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_test.shape",
   "id": "ef6b07c8a7c6a507",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# adding bias to feature column:\n",
    "test_ones = np.ones((test.shape[0], 1))\n",
    "testX_bias = np.hstack([test_ones, X_test])"
   ],
   "id": "5485802bb587b65e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "testX_bias.shape",
   "id": "9465d11efbb565fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prediction of test\n",
    "test_pred = np.dot(testX_bias, best_weights)\n",
    "test_pred"
   ],
   "id": "7517afcc8040ed73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_pred.shape",
   "id": "752e4dd21cb1ebde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mse for test:\n",
    "mse_test = np.mean((test_pred-y_test) ** 2)\n",
    "mse_test"
   ],
   "id": "a2b1fbd5cafbcae0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.min(y_test)",
   "id": "8af5d066d28c7510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.max(y_test)",
   "id": "f27efd71d3ec0c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.std(y_test)",
   "id": "90f65e5be6cd3889",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Question 1A - Normalized Housing Dataset",
   "id": "f3288d5c68612689"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house_train = np.loadtxt(\"housing_data/train.txt\")\n",
    "house_test = np.loadtxt(\"housing_data/test.txt\")\n",
    "\n",
    "house_train.shape"
   ],
   "id": "1d265f3d7ed04b96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# separating features and labels\n",
    "X_train = house_train[:, :-1]\n",
    "y_train = house_train[:, -1]\n",
    "X_test = house_test[:, :-1]\n",
    "y_test = house_test[:, -1]"
   ],
   "id": "3651f6cf593e95b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# applying normalization -\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train_normalized = (X_train - train_mean) / train_std\n",
    "X_test_normalized = (X_test - train_mean) / train_std\n",
    "\n",
    "X_train_normalized[:3]"
   ],
   "id": "bbc590fe0721ff8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# adding bias to X_train and X_test\n",
    "ones_col_Xtrain = np.ones((X_train_normalized.shape[0], 1))\n",
    "ones_col_Xtest = np.ones((X_test_normalized.shape[0], 1))\n",
    "\n",
    "houseXtrain_bias = np.hstack([ones_col_Xtrain, X_train_normalized])\n",
    "houseXtest_bias = np.hstack([ones_col_Xtest, X_test_normalized])"
   ],
   "id": "1517638420637af3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using normal equation:\n",
    "\n",
    "houseXtrain_transpose = houseXtrain_bias.T\n",
    "\n",
    "houseXtrain_dot = np.dot(houseXtrain_transpose, houseXtrain_bias)\n",
    "\n",
    "houseXtrain_inverse = np.linalg.inv(houseXtrain_dot)\n",
    "\n",
    "houseXtrain_y_dot = np.dot(houseXtrain_transpose, y_train)\n",
    "\n",
    "house_train_theta = np.dot(houseXtrain_inverse, houseXtrain_y_dot)\n",
    "house_train_theta"
   ],
   "id": "4e285ec22c427342",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house_train_pred = np.dot(houseXtrain_bias, house_train_theta)\n",
    "\n",
    "house_test_pred = np.dot(houseXtest_bias, house_train_theta)"
   ],
   "id": "4445188d742d2437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# errors:\n",
    "house_train_mse = np.mean((house_train_pred - y_train) ** 2)\n",
    "house_test_mse = np.mean((house_test_pred - y_test) ** 2)"
   ],
   "id": "54e7213bca42b4dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Housing dataset training mse: {house_train_mse}\")",
   "id": "241a3af9fd93ef8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Housing dataset testing mse: {house_test_mse}\")",
   "id": "23354e3a601e5462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question1A - Spam Dataset Work\n",
    "with normalization , kfold cross validation and binary predictions"
   ],
   "id": "8573243cfdd53844"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SPAM dataset loading\n",
    "data = np.loadtxt(\"spambase/spambase.data\", delimiter=\",\")"
   ],
   "id": "230d62cb15dd1df4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "49b74c566722ae0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.shape",
   "id": "d408b890c3b650a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "ones_col = np.ones((X.shape[0], 1))\n",
    "spamX_bias = np.hstack([ones_col, X])\n",
    "\n",
    "spamX_bias.shape"
   ],
   "id": "9f52eece1e00722c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamX_bias[:5]",
   "id": "150fa2bb2a7ef91d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# applying normal equation\n",
    "# taking transpose:\n",
    "spamX_t = spamX_bias.T\n",
    "\n",
    "# multiplying X_t and X:\n",
    "spamX_dot = np.dot(spamX_t, spamX_bias)\n",
    "\n",
    "# taking inverse:\n",
    "spamX_inv_1 = np.linalg.inv(spamX_dot)\n",
    "\n",
    "# calculation for second term\n",
    "spamXy_dot = np.dot(spamX_t, y)\n",
    "\n",
    "best_weights = np.dot(spamX_inv_1, spamXy_dot)\n",
    "best_weights"
   ],
   "id": "b72019be121d2358",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spamy_pred = np.dot(spamX_bias, best_weights)\n",
    "\n",
    "# threshold :\n",
    "threshold = 0.431\n",
    "binary_pred = (spamy_pred > threshold).astype(int)\n",
    "\n",
    "binary_pred.shape"
   ],
   "id": "2694c988d6e7c776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# accuracy evaluation\n",
    "accuracy = np.mean(binary_pred == y)\n",
    "accuracy"
   ],
   "id": "a0b7fa1a2c82a3e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spam_min = np.min(spamy_pred)\n",
    "spam_max = np.max(spamy_pred)"
   ],
   "id": "308ae0c78221cc2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spam_min",
   "id": "a1f0b8f37167d0d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spam_max",
   "id": "81db67206d1ac828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### K-Fold cross validation working on Spam dataset",
   "id": "e72b474dfda8cae8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = np.loadtxt(\"spambase/spambase.data\", delimiter=\",\")\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:,-1]"
   ],
   "id": "8e30bc6194e2de50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_fold_accuracies = []\n",
    "test_fold_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold = X[train_index]\n",
    "    X_test_fold = X[test_index]\n",
    "\n",
    "    y_train_fold = y[train_index]\n",
    "    y_test_fold = y[test_index]\n",
    "\n",
    "    # adding normalization:\n",
    "    train_mean = np.mean(X_train_fold, axis=0)\n",
    "    train_std = np.std(X_train_fold, axis=0)\n",
    "\n",
    "    X_train_normalized = (X_train_fold - train_mean) / train_std\n",
    "    X_test_normalized = (X_test_fold - train_mean) / train_std\n",
    "\n",
    "    # adding bias:\n",
    "    ones_col_Xtrain = np.ones((X_train_normalized.shape[0], 1))\n",
    "    ones_col_Xtest = np.ones((X_test_normalized.shape[0], 1))\n",
    "\n",
    "    spam_Xtrain_bias = np.hstack([ones_col_Xtrain, X_train_normalized])\n",
    "    spam_Xtest_bias = np.hstack([ones_col_Xtest, X_test_normalized])\n",
    "\n",
    "    # model training\n",
    "    spamXtrain_T = spam_Xtrain_bias.T\n",
    "\n",
    "    spamXtrain_dot = np.dot(spamXtrain_T, spam_Xtrain_bias)\n",
    "\n",
    "    spamXtrain_inverse = np.linalg.inv(spamXtrain_dot)\n",
    "\n",
    "    spamX_y_dot = np.dot(spamXtrain_T, y_train_fold)\n",
    "\n",
    "    best_weights_X = np.dot(spamXtrain_inverse, spamX_y_dot)\n",
    "\n",
    "    # predictions:\n",
    "    train_continuous_predictions = np.dot(spam_Xtrain_bias, best_weights_X)\n",
    "    test_continuous_predictions = np.dot(spam_Xtest_bias, best_weights_X)\n",
    "\n",
    "    # threshold for binary classification:\n",
    "    threshold = 0.43\n",
    "    test_binary_pred = (test_continuous_predictions > threshold).astype(int)\n",
    "    train_binary_pred = (train_continuous_predictions > threshold).astype(int)\n",
    "\n",
    "\n",
    "    # accuracy:\n",
    "    test_fold_accuracy = np.mean(test_binary_pred == y_test_fold)\n",
    "    train_fold_accuracy = np.mean(train_binary_pred == y_train_fold)\n",
    "    test_fold_accuracies.append(test_fold_accuracy)\n",
    "    train_fold_accuracies.append(train_fold_accuracy)\n",
    "\n",
    "test_mean_accuracy = np.mean(test_fold_accuracies)\n",
    "train_mean_accuracy = np.mean(train_fold_accuracies)\n",
    "\n",
    "print(f\"Testing accuracy: {test_mean_accuracy * 100}\")\n",
    "print(f\"Training accuracy: {train_mean_accuracy * 100}\")"
   ],
   "id": "702b0cf27d326f4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Question 1B - L2 Regularization",
   "id": "44f5f07daf867907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loading datasets both housing and spam\n",
    "import numpy as np\n",
    "house_data_train = np.loadtxt(\"housing_data/train.txt\")\n",
    "house_data_test = np.loadtxt(\"housing_data/test.txt\")\n",
    "\n",
    "spam_data = np.loadtxt(\"spambase/spambase.data\", delimiter=\",\")"
   ],
   "id": "5505929907ba8b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "first going with housing dataset",
   "id": "30d7a121b75be4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# splitting data into train and test\n",
    "house_X = house_data_train[:,:-1]\n",
    "house_y = house_data_train[:, -1]"
   ],
   "id": "73a34c9461c8b8f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalization step:\n",
    "house_train_mean = np.mean(house_X, axis=0)\n",
    "house_train_std = np.std(house_X, axis=0)\n",
    "\n",
    "house_X_norm = (house_X-house_train_mean) / house_train_std\n",
    "house_X_norm[:3]"
   ],
   "id": "8d220ae3abb96479",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# adding bias\n",
    "ones_col = np.ones((house_X_norm.shape[0], 1))\n",
    "house_X_with_bias = np.hstack([ones_col, house_X_norm])\n",
    "\n",
    "house_X_with_bias[:3]"
   ],
   "id": "e5ee607f5bdbb282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "L2 Regularization Equation:\n",
    "$ \\theta = (X^TX + \\lambda I) X^T Y $"
   ],
   "id": "19e18f9de14a9df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using normal equation\n",
    "lambda_1 = 0.43\n",
    "\n",
    "house_X_transpose = house_X_with_bias.T\n",
    "\n",
    "dot_X = np.dot(house_X_transpose, house_X_with_bias)  # first term\n",
    "\n",
    "I_house = np.eye(house_X_with_bias.shape[1])\n",
    "\n",
    "dot_lambda = lambda_1 * I_house # second term\n",
    "\n",
    "add_X_lambda = dot_X + dot_lambda\n",
    "\n",
    "inverse_X_with_lambda = np.linalg.inv(add_X_lambda)\n",
    "\n",
    "XTy = np.dot(house_X_transpose, house_y)\n",
    "\n",
    "house_ridge_weights = np.dot(inverse_X_with_lambda, XTy)\n",
    "\n",
    "house_ridge_weights"
   ],
   "id": "a5e91db69791d18b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_eval_mse = np.dot(house_X_with_bias, house_ridge_weights)\n",
    "\n",
    "final_mse_1 = np.mean((train_eval_mse - house_y)**2)"
   ],
   "id": "d0d0a07b13c87e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Training MSE: {final_mse_1}\") # training mse",
   "id": "401495757cb3e260",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test mse working:\n",
    "house_X_test = house_data_test[:,:-1]\n",
    "house_y_test = house_data_test[:,-1]\n",
    "\n",
    "house_X_test_norm = (house_X_test - house_train_mean) / house_train_std\n",
    "\n",
    "ones_col_test = np.ones((house_X_test_norm.shape[0], 1))\n",
    "house_X_test_bias = np.hstack([ones_col_test, house_X_test_norm])\n",
    "\n",
    "house_pred_test = np.dot(house_X_test_bias, house_ridge_weights)\n",
    "mse_house_test = np.mean((house_pred_test - house_y_test) ** 2)\n",
    "print(f\"Testing MSE: {mse_house_test}\")"
   ],
   "id": "1be65adeee8523a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Spam dataset Working - L2 Regularization :  $ \\theta = (X^TX + \\lambda I) X^T Y $",
   "id": "e5c11ecb80983791"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define lambda values to test\n",
    "lambda_values = np.logspace(-2, 1, 7)\n",
    "results = []\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    print(f\"Testing λ = {lambda_val}\")\n",
    "\n",
    "    train_fold_accuracies = []\n",
    "    test_fold_accuracies = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_fold = X[train_index]\n",
    "        X_test_fold = X[test_index]\n",
    "        y_train_fold = y[train_index]\n",
    "        y_test_fold = y[test_index]\n",
    "\n",
    "        # normalization:\n",
    "        train_mean = np.mean(X_train_fold, axis=0)\n",
    "        train_std = np.std(X_train_fold, axis=0)\n",
    "        X_train_normalized = (X_train_fold - train_mean) / train_std\n",
    "        X_test_normalized = (X_test_fold - train_mean) / train_std\n",
    "\n",
    "        # adding bias:\n",
    "        ones_col_Xtrain = np.ones((X_train_normalized.shape[0], 1))\n",
    "        ones_col_Xtest = np.ones((X_test_normalized.shape[0], 1))\n",
    "        spam_Xtrain_bias = np.hstack([ones_col_Xtrain, X_train_normalized])\n",
    "        spam_Xtest_bias = np.hstack([ones_col_Xtest, X_test_normalized])\n",
    "\n",
    "        # Ridge regression\n",
    "        spamXtrain_T = spam_Xtrain_bias.T\n",
    "        spamXtrain_dot = np.dot(spamXtrain_T, spam_Xtrain_bias)\n",
    "        I_lambda = np.eye(spamXtrain_dot.shape[1])\n",
    "        add_X_lambda = spamXtrain_dot + lambda_val * I_lambda  # Use current lambda\n",
    "        spamXtrain_inverse = np.linalg.inv(add_X_lambda)\n",
    "        spamX_y_dot = np.dot(spamXtrain_T, y_train_fold)\n",
    "        best_weights_X = np.dot(spamXtrain_inverse, spamX_y_dot)\n",
    "\n",
    "        # predictions and accuracy\n",
    "        train_continuous_pred = np.dot(spam_Xtrain_bias, best_weights_X)\n",
    "        test_continuous_pred = np.dot(spam_Xtest_bias, best_weights_X)\n",
    "\n",
    "        threshold = 0.43\n",
    "        test_binary_pred = (test_continuous_pred > threshold).astype(int)\n",
    "        train_binary_pred = (train_continuous_pred > threshold).astype(int)\n",
    "\n",
    "        test_fold_accuracy = np.mean(test_binary_pred == y_test_fold)\n",
    "        train_fold_accuracy = np.mean(train_binary_pred == y_train_fold)\n",
    "\n",
    "        test_fold_accuracies.append(test_fold_accuracy)\n",
    "        train_fold_accuracies.append(train_fold_accuracy)\n",
    "\n",
    "    # Average across folds\n",
    "    avg_train = np.mean(train_fold_accuracies)\n",
    "    avg_test = np.mean(test_fold_accuracies)\n",
    "\n",
    "    results.append((lambda_val, avg_train, avg_test))\n",
    "    print(f\"λ={lambda_val}: Train={avg_train:.3f}, Test={avg_test:.3f}\")"
   ],
   "id": "4e96dee4367c59ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_accuracies = [result[1] for result in results]\n",
    "test_accuracies = [result[2] for result in results]\n",
    "\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"Average Training Accuracy: {np.mean(train_accuracies)*100:.1f}%\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies)*100:.1f}%\")\n",
    "print(f\"Best Test Accuracy: {np.max(test_accuracies)*100:.1f}%\")\n",
    "print(f\"Average Generalization Gap: {np.mean([r[1]-r[2] for r in results])*100:.1f}%\")"
   ],
   "id": "d355ec1826cca8f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_accuracies = [result[1] for result in results]\n",
    "test_accuracies = [result[2] for result in results]\n",
    "\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"Average Training Accuracy: {np.mean(train_accuracies)*100:.1f}%\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies)*100:.1f}%\")\n",
    "print(f\"Average Generalization Gap: {np.mean([r[1]-r[2] for r in results])*100:.1f}%\")\n",
    "\n",
    "best_test_idx = np.argmax(test_accuracies)\n",
    "worst_test_idx = np.argmin(test_accuracies)\n",
    "\n",
    "print(f\"\\nBEST PERFORMANCE:\")\n",
    "print(f\"Lambda: {results[best_test_idx][0]:.3f}\")\n",
    "print(f\"Train Accuracy: {results[best_test_idx][1]*100:.1f}%\")\n",
    "print(f\"Test Accuracy: {results[best_test_idx][2]*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nWORST PERFORMANCE:\")\n",
    "print(f\"Lambda: {results[worst_test_idx][0]:.3f}\")\n",
    "print(f\"Train Accuracy: {results[worst_test_idx][1]*100:.1f}%\")\n",
    "print(f\"Test Accuracy: {results[worst_test_idx][2]*100:.1f}%\")"
   ],
   "id": "2620357b2dcd6628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "81ba10bb18f8f478",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
